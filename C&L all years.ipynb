{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ff3886-fec6-40c1-b27c-9e7c535a2405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\julia\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\julia\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\julia\\anaconda3\\lib\\site-packages (2.0.25)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (2.9.9)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\julia\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl sqlalchemy psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3e5162-020e-4f3b-a70a-b7cc75ca0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e8dd94-3803-4b63-a4a7-1b231eb7056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify base directory\n",
    "base_directory = r'C:\\Users\\julia\\Projects\\SRoses\\Production'\n",
    "\n",
    "def read_files(base_directory, production_files=False):\n",
    "    data_frames = []\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                if production_files:\n",
    "                    # Only include files named \"Production\"\n",
    "                    if file.lower().startswith('production') and file.endswith('.csv'):\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        data_frames.append(df)\n",
    "                else:\n",
    "                    # Exclude files named \"Production\"\n",
    "                    if file.lower().startswith('production'):\n",
    "                        continue\n",
    "                    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "                        df = pd.read_excel(file_path)\n",
    "                    elif file.endswith('.csv'):\n",
    "                        df = pd.read_csv(file_path)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract year, month, day from date column\n",
    "                    if 'Date' in df.columns:\n",
    "                        df['Year'] = pd.to_datetime(df['Date']).dt.year\n",
    "                        df['Month'] = pd.to_datetime(df['Date']).dt.month\n",
    "                        df['Day'] = pd.to_datetime(df['Date']).dt.day\n",
    "                        \n",
    "                        # Filter data for years 2022, 2023, and 2024\n",
    "                        df = df[df['Year'].isin([2022, 2023, 2024])]\n",
    "                        \n",
    "                    data_frames.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    return data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f622e73-5f70-49a5-bceb-22230f771d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_upload(df, file_name, table_name, engine):\n",
    "    os.makedirs('data/processed', exist_ok=True)\n",
    "    csv_path = f'data/processed/{file_name}'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Combined data saved successfully to {csv_path}.\")\n",
    "    \n",
    "    try:\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"Data loaded into SQL Server successfully into table {table_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data into SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9233161-187c-4475-b103-539a60afae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved successfully to data/processed/combined_data.csv.\n",
      "Data loaded into SQL Server successfully into table combined_data.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define SQL Server connection parameters\n",
    "    server = 'server' #include needed server\n",
    "    database = 'database' #include needed database\n",
    "    username = 'username' #include needed username\n",
    "    password = 'password' #include needed password\n",
    "    driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}'\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Read non-Production files\n",
    "    data_frames = read_files(base_directory)\n",
    "    if data_frames:\n",
    "        combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "        save_and_upload(combined_df, 'combined_data.csv', 'combined_data', engine)\n",
    "    else:\n",
    "        print(\"No data frames to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbb7c9-3968-4d56-9adb-efdd66c7db05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
